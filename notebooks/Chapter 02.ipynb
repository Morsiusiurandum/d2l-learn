{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归\n",
    "\n",
    "$ x^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正态分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:38:42.081537Z",
     "start_time": "2024-07-09T14:38:39.893652Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def normal_distribution(_x, _mu, _sigma):\n",
    "    p = 1 / math.sqrt(2 * math.pi * _sigma ** 2)\n",
    "    return p * np.exp(-0.5 / _sigma ** 2 * (_x - _mu) ** 2)\n",
    "\n",
    "\n",
    "x = np.arange(-7, 7, 0.01)\n",
    "\n",
    "# 均值和标准差对\n",
    "params = [(0, 1), (0, 2), (3, 1)]\n",
    "\n",
    "for mu, sigma in params:\n",
    "    plt.plot(x, normal_distribution(x, mu, sigma), label=f'mean {mu}, standard-deviation {sigma}')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('p(x)')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 人造数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:38:42.254445Z",
     "start_time": "2024-07-09T14:38:42.081537Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ⽣成y=Xw+b+噪声的合成数据函数\n",
    "def synthetic_data(w, b, num_examples):\n",
    "    X = torch.normal(0, 1, (num_examples, len(w)))  # 生成均值为0，标准差为1的正态分布随机特征数据\n",
    "    y = torch.matmul(X, w) + b  # 计算标签y，y=Xw+b\n",
    "    y += torch.normal(0, 0.01, y.shape)  # 添加均值为0，标准差为0.01的噪声\n",
    "    return X, y.reshape((-1, 1))  # 返回特征数据X和标签数据y，将y reshape为列向量\n",
    "\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])  # 真实的权重向量w\n",
    "true_b = 4.2  # 真实的偏置b\n",
    "features, labels = synthetic_data(true_w, true_b, 1000)  # 生成1000个样本的合成数据\n",
    "\n",
    "# 绘制特征(features)的第二列和对应标签(labels)的散点图\n",
    "plt.scatter(features[:, 1].detach().numpy(), labels.detach().numpy(), 1)\n",
    "# x轴标签\n",
    "plt.xlabel('Feature 2')\n",
    "# y轴标签\n",
    "plt.ylabel('Label')\n",
    "plt.title('Synthetic Data Scatter Plot')\n",
    "# 显示散点图\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:38:42.475432Z",
     "start_time": "2024-07-09T14:38:42.256453Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "\n",
    "def data_iter(batch_size, features, labels):\n",
    "    \"\"\"生成随机顺序的小批量样本\"\"\"\n",
    "    num_examples = len(features)  # 获取样本数量\n",
    "    indices = list(range(num_examples))  # 创建样本索引列表\n",
    "    random.shuffle(indices)  # 将样本索引列表随机打乱，用于随机读取样本\n",
    "\n",
    "    # 生成每个batch的样本集合\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices = torch.tensor(indices[i: min(i + batch_size, num_examples)])  # 获取当前batch的样本索引\n",
    "        yield features[batch_indices], labels[batch_indices]  # 返回当前batch的特征和标签\n",
    "\n",
    "\n",
    "w = torch.normal(0, 0.01, size=(2, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "\n",
    "def linreg(X, w, b):\n",
    "    \"\"\"线性回归模型\"\"\"\n",
    "    return torch.matmul(X, w) + b\n",
    "\n",
    "\n",
    "def squared_loss(y_hat, y):\n",
    "    \"\"\"均⽅损失\"\"\"\n",
    "    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2\n",
    "\n",
    "\n",
    "def sgd(params, lr, batch_size):\n",
    "    \"\"\"⼩批量随机梯度下降\n",
    "    :param params: 要更新的参数列表\n",
    "    :param lr: 学习率\n",
    "    :param batch_size: 批量大小\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad / batch_size\n",
    "    param.grad.zero_()\n",
    "\n",
    "\n",
    "# 设置超参数\n",
    "lr = 0.03\n",
    "num_epochs = 20\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "batch_size = 90\n",
    "\n",
    "# 外部循环遍历每个epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # 内部循环遍历数据的每个batch\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        # 计算当前batch的损失\n",
    "        l = loss(net(X, w, b), y)\n",
    "        # 求损失函数关于[w, b]的梯度\n",
    "        l.sum().backward()\n",
    "        # 使用随机梯度下降（SGD）更新参数[w, b]\n",
    "        sgd([w, b], lr, batch_size)\n",
    "\n",
    "    # 完成一个epoch后，计算整体的训练损失\n",
    "    with torch.no_grad():\n",
    "        train_l = loss(net(features, w, b), labels)\n",
    "        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:38:43.851330Z",
     "start_time": "2024-07-09T14:38:42.475432Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "features, labels = synthetic_data(true_w, true_b, 1000)\n",
    "\n",
    "\n",
    "def load_array(data_arrays, batch_size, is_train=True):  #@save\n",
    "    \"\"\"构造⼀个PyTorch数据迭代器\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "data_iter = load_array((features, labels), batch_size)\n",
    "\n",
    "net = nn.Sequential(nn.Linear(2, 1))\n",
    "\n",
    "net[0].weight.data.normal_(0, 0.01)\n",
    "net[0].bias.data.fill_(0)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.03)\n",
    "\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter:\n",
    "        l = loss(net(X), y)\n",
    "        trainer.zero_grad()\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "    l = loss(net(features), labels)\n",
    "    print(f'epoch {epoch + 1}, loss {l:f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## softmax回归\n",
    "\n",
    "### 分类问题\n",
    "\n",
    "假设每次输⼊是⼀个2 × 2的灰度图像。我们可以⽤⼀个标量表⽰每个像素值，\n",
    "每个图像对应四个特征$x_1, x_2, x_3, x_4$。此外，假设每个图像属于类别“猫”“鸡”和“狗”中的⼀个\n",
    "\n",
    "使用独热编码（one-hot encoding）。独热编码是⼀个向量，它的分量和类别⼀样多。\n",
    "类别对应的分量设置为1，其他所有分量设置为0。\n",
    "\n",
    "例如：标签${\\bf{y}}$将是⼀个三维向量，其中(1, 0, 0)对应于“猫”、(0, 1, 0)对应于“鸡”、(0, 0, 1)对应于“狗”，那么输出${\\bf{y}}$就可以表示为：\n",
    "\n",
    "$$\n",
    "{\\bf{y}} \\in {\\begin{Bmatrix} (1,0,0), & (0,1,0), & (0,0,1) \\end{Bmatrix}}\n",
    "$$\n",
    "\n",
    "为了估计所有可能类别的条件概率，需要⼀个有多个输出的模型，每个类别对应⼀个输出。\n",
    "为了解决线性模型的分类问题，需要和输出⼀样多的仿射函数（affine function），每个输出对应于它⾃⼰的仿射函数。\n",
    "\n",
    "在上述例子中，可以组成一个方程组：\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "    {y_1} = {w_{11}}{x_1} + {w_{12}}{x_2} + {w_{13}}{x_3} + {w_{14}}{x_4} \\\\\n",
    "    {y_2} = {w_{21}}{x_1} + {w_{22}}{x_2} + {w_{23}}{x_3} + {w_{24}}{x_4} \\\\\n",
    "    {y_3} = {w_{31}}{x_1} + {w_{32}}{x_2} + {w_{33}}{x_3} + {w_{34}}{x_4} \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "同样使用线性代数表示：\n",
    "\n",
    "$$\n",
    "    {\\bf{y}} = {\\bf{W}} {\\bf{x}} + {\\bf{b}}\n",
    "    \\quad \\text{其中} \\quad\n",
    "    {\\bf{b}} \\text{是一个偏置值}\n",
    "$$\n",
    "\n",
    "### softmax运算\n",
    "\n",
    "$$\n",
    "{\\widehat{\\bf{y}}} = softmax({\\bf{o}}) \n",
    "\\quad \\text{其中} \\quad\n",
    "{\\widehat{y}_i} = \\frac{exp({o_i})}{\\sum_{k=1}^{n}{exp({o_k})} }\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:38:43.858176Z",
     "start_time": "2024-07-09T14:38:43.851330Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
